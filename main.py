# main.py
# ì‹¤í–‰: uvicorn main:app --reload
# í•„ìš” íŒ¨í‚¤ì§€:
# pip install fastapi uvicorn python-dotenv openai langchain langchain-openai langchain-core sentence-transformers pandas numpy

import os
import json
import re
import ast
import pandas as pd
import numpy as np

from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from sentence_transformers import SentenceTransformer
from openai import OpenAI

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from recommendation_models import RecommendationSummaryRequest, RecommendationSummaryResponse


# ======================================================
# 0) ê¸°ë³¸ ì„¤ì •
# ======================================================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env í™•ì¸í•˜ì„¸ìš”.")

# OpenAI ê³µì‹ SDK(í•„ìš”í•˜ë©´ ì‚¬ìš©)
client = OpenAI(api_key=OPENAI_API_KEY)

# LangChain LLM
llm = ChatOpenAI(
    api_key=OPENAI_API_KEY,
    model="gpt-4o-mini",
    temperature=0.2,
    max_tokens=512,
)

app = FastAPI(title="ë§¥ë½ + ì„±ì  + í•™êµí‰ì  ê¸°ë°˜ ëŒ€í•™ ì¶”ì²œ API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)


# ======================================================
# 1) ì„¸ì…˜ ë©”ëª¨ë¦¬ (ì„œë²„ ì¸ë©”ëª¨ë¦¬)
# - ì‹¤ì œ ì„œë¹„ìŠ¤ë©´ Redis/DBë¡œ êµì²´ ê¶Œì¥
# ======================================================
conversation_store: dict[str, list[dict]] = {}
MAX_TURNS = 12  # ìµœê·¼ 12í„´ ì •ë„ë§Œ ìœ ì§€(ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ë¹„ìš©/í† í° ì¦ê°€)

def get_history(session_id: str) -> list[dict]:
    return conversation_store.get(session_id, [])

def append_history(session_id: str, role: str, content: str):
    conversation_store.setdefault(session_id, []).append({"role": role, "content": content})
    # ê¸¸ì´ ì œí•œ
    if len(conversation_store[session_id]) > MAX_TURNS * 2:
        conversation_store[session_id] = conversation_store[session_id][-MAX_TURNS * 2 :]

def history_to_text(history: list[dict]) -> str:
    if not history:
        return "ì—†ìŒ"
    lines = []
    for m in history:
        r = "ì‚¬ìš©ì" if m["role"] == "user" else "ìƒë‹´ë´‡"
        lines.append(f"{r}: {m['content']}")
    return "\n".join(lines)


# ======================================================
# 2) ìœ í‹¸
# ======================================================
def normalize_text(text: str) -> str:
    text = str(text)
    text = re.sub(r"[,\u00b7ãƒ»]", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def extract_grade(text: str):
    # "ë‚´ì‹  2.7", "2.7" ê°™ì€ ì¼€ì´ìŠ¤ ëŒ€ì‘(ì›í•˜ëŠ” ê·œì¹™ ë” ê°•í™” ê°€ëŠ¥)
    match = re.search(r"(?:ë‚´ì‹ \s*)?(\d(?:\.\d+)?)", text)
    return float(match.group(1)) if match else None

def safe_float(x):
    try:
        return float(x)
    except:
        return None


# ======================================================
# 3) LangChain ì²´ì¸ë“¤ (Intent / Answer)
# ======================================================
def build_chain(template: str):
    prompt = ChatPromptTemplate.from_template(template)
    return prompt | llm | StrOutputParser()


# ì„ íƒ: ì˜ë„ ë¶„ë¥˜(ë©€í‹°ì²´ì¸ê¹Œì§€ëŠ” ì•„ë‹ˆê³ , í›„ì²˜ë¦¬ ë¶„ê¸° ì •ë„ì— ì‚¬ìš©)
INTENT_PROMPT = """
ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ ë¶„ë¥˜í•œë‹¤.
ì•„ë˜ ë¼ë²¨ ì¤‘ í•˜ë‚˜ë§Œ ì •í™•íˆ ì¶œë ¥í•´ë¼(ë‹¤ë¥¸ ë§ ê¸ˆì§€).

ë¼ë²¨:
- RECOMMEND: ì¡°ê±´ì— ë§ëŠ” ëŒ€í•™/í•™ê³¼ë¥¼ ì¶”ì²œí•´ë‹¬ë¼ëŠ” ìš”ì²­
- SCHOOL_INFO: íŠ¹ì • í•™êµ/í•™ê³¼ í•˜ë‚˜ì— ëŒ€í•œ ì •ë³´ ìš”ì²­(ì˜ˆ: ì„±ê· ê´€ëŒ€ ì»´ê³µ ì–´ë•Œ?)
- EXPLAIN_SYSTEM: ì‹œìŠ¤í…œ/ì½”ë“œ/êµ¬ì¡° ì„¤ëª… ìš”ì²­
- OTHER: ê·¸ ì™¸

ì§ˆë¬¸:
{question}

ë¼ë²¨:
"""

# ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸(ì¶”ì²œ/ë‹¨ì¼í•™êµ/ì„¤ëª… ëª¨ë‘ ì»¤ë²„)
ANSWER_PROMPT = """
ë„ˆëŠ” ì…ì‹œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëƒ‰ì² í•˜ê³  í˜„ì‹¤ì ì¸ ì¡°ì–¸ì„ í•´ì£¼ëŠ” 'ì§„í•™ ë‹´ë‹¹ ì„ ìƒë‹˜'ì´ë‹¤.
í•™ìƒì˜ ì¸ìƒì´ ë‹¬ë¦° ë¬¸ì œë‹¤. í¬ë§ ê³ ë¬¸ í•˜ì§€ ë§ê³  ë°ì´í„°ì— ê·¼ê±°í•´ ì†”ì§í•˜ê²Œ ë§í•´ë¼.

[í•„ìˆ˜ ê·œì¹™]
1. **ì¤‘ë³µ ê¸ˆì§€**: ì ˆëŒ€ ê°™ì€ í•™êµ/í•™ê³¼ ì„¤ëª…ì„ ë‘ ë²ˆ ë°˜ë³µí•˜ì§€ ë§ˆë¼.
2. **ìˆ«ì ë‚˜ì—´ ê¸ˆì§€**: "í•™ë¬¸í‰íŒ=68.4" ì²˜ëŸ¼ ê¸°ê³„ì ìœ¼ë¡œ ë§í•˜ì§€ ë§ê³ , "í•™ë¬¸ì  ì„±ê³¼ê°€ ë§¤ìš° ìš°ìˆ˜í•˜ë©°(68.4ì )..." ì²˜ëŸ¼ ë¬¸ì¥ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë¼.
3. **í˜„ì‹¤ì  ì¡°ì–¸**: 
   - í•™ìƒ ë‚´ì‹ ì´ í‰ê·  ë‚´ì‹ ë³´ë‹¤ 0.5ë“±ê¸‰ ì´ìƒ ë‚®ìœ¼ë©´ "ìƒí–¥ ì§€ì›"ì„ì„ ë¶„ëª…íˆ í•˜ê³ , í•©ê²©ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒì„ ê²½ê³ í•´ë¼.
   - ë¬´ì¡°ê±´ "ì í•©í•˜ë‹¤"ê³  í•˜ì§€ ë§ê³ , ì„±ì ì´ ë¶€ì¡±í•˜ë©´ ì„±ì  ë¦¬ìŠ¤í¬ë¥¼ ë¨¼ì € ì–¸ê¸‰í•´ë¼.

[ì…ë ¥ ì •ë³´]
- ì´ì „ ëŒ€í™”: {history}
- ì‚¬ìš©ì ì§ˆë¬¸: {question}
- ì˜ë„: {intent}
- ê²€ìƒ‰ëœ ëŒ€í•™ ë°ì´í„°: 
{context}

[ë‹µë³€ ê°€ì´ë“œ]
1. **intentê°€ RECOMMEND(ì¶”ì²œ)ì¼ ë•Œ**:
   - ê²€ìƒ‰ëœ í›„ë³´ ì¤‘ ê°€ì¥ ì í•©í•œ 3ê°œ ì •ë„ë§Œ ì¶”ë ¤ì„œ ë³´ì—¬ì¤˜.
   - ê° ëŒ€í•™ë³„ë¡œ:
     (1) [ëŒ€í•™ëª… / í•™ê³¼ëª…] (ì§€ì—­)
     (2) ë‚´ì‹  ë¶„ì„: í•™ìƒ ë‚´ì‹  vs í‰ê·  ë‚´ì‹  ë¹„êµ. (ì•ˆì „/ì ì •/ìƒí–¥/ìœ„í—˜ íŒì •)
     (3) í•µì‹¬ ê°•ì : í•™êµ í‰íŒ, ì·¨ì—…ë¥  ë“± ì§€í‘œë¥¼ í™œìš©í•´ ì´ í•™êµì˜ ì¥ì ì„ ì„œìˆ í˜•ìœ¼ë¡œ ìš”ì•½.
     (4) ì„ ìƒë‹˜ì˜ í•œë§ˆë””: ì™œ ì´ í•™ìƒì—ê²Œ ì¶”ì²œí•˜ëŠ”ì§€, ì£¼ì˜í•  ì ì€ ë¬´ì—‡ì¸ì§€.

2. **intentê°€ SCHOOL_INFO(ìƒì„¸ì •ë³´)ì¼ ë•Œ**:
   - ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¸ **ë”± ê·¸ í•™êµ/í•™ê³¼ í•˜ë‚˜**ì— ëŒ€í•´ì„œë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ ë¶„ì„í•´ë¼. (ë‹¤ë¥¸ í•™êµ ì–¸ê¸‰ X)
   - ì§€í‘œ ì ìˆ˜ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , ê·¸ ì ìˆ˜ê°€ ì˜ë¯¸í•˜ëŠ” ë°”(ì˜ˆ: ì—°êµ¬ë ¥ì´ ì¢‹ë‹¤, ì·¨ì—…ì´ ì˜ ëœë‹¤)ë¥¼ ì„¤ëª…í•´ë¼.
   - **ê°€ì¥ ì¤‘ìš”í•œ ê±´ ë‚´ì‹  ì í•©ì„±ì´ë‹¤.** ì„±ì  ì°¨ì´ê°€ í¬ë©´ ëƒ‰ì •í•˜ê²Œ ë§í•´ì¤˜ë¼.

3. ë‹µë³€ì€ ì¹œì ˆí•˜ì§€ë§Œ ë‹¨í˜¸í•œ 'í•´ìš”ì²´'ë¥¼ ì‚¬ìš©í•´ë¼.
4. ê°€ë…ì„±ì„ ìœ„í•´ ë¶ˆí•„ìš”í•œ ì¤„ë°”ê¿ˆì´ë‚˜ ê¸°í˜¸ë¥¼ ë‚¨ë°œí•˜ì§€ ë§ˆë¼.
"""

FALLBACK_PROMPT = """
ë„ˆëŠ” ëŒ€í•™Â·í•™ê³¼ ì§„í•™ ìƒë‹´ì„ ë•ëŠ” ì±—ë´‡ì´ë‹¤.

ì¤‘ìš”: ì§€ê¸ˆì€ ë‚´ë¶€ RAG(í•™ê³¼/í‰íŒ/ë‚´ì‹  ë°ì´í„°)ì—ì„œ ì¶©ë¶„í•œ ê·¼ê±°ë¥¼ ì°¾ì§€ ëª»í–ˆë‹¤.
ê·¸ëŸ¬ë¯€ë¡œ íŠ¹ì • ëŒ€í•™/í•™ê³¼ì˜ 'í‰ê·  ë‚´ì‹ 'ì´ë‚˜ 'í‰íŒ ì ìˆ˜' ê°™ì€ ìˆ˜ì¹˜ë¥¼ ì§€ì–´ë‚´ë©´ ì•ˆ ëœë‹¤.

í•  ì¼:
1) ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì§„ ì •ë³´ ìˆ˜ì¤€ì—ì„œ ì„¤ëª…í•œë‹¤.
2) ì •í™•í•œ ì¶”ì²œì„ ìœ„í•´ í•„ìš”í•œ ì¶”ê°€ ì§ˆë¬¸ 2~4ê°œë¥¼ ì œì‹œí•œë‹¤.
3) ë‹µë³€ì€ ì¹œì ˆí•œ í•´ìš”ì²´ë¡œ, ê³¼ì¥ ì—†ì´ ë§í•œë‹¤.
4) ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ê³ , í™•ì¸ ë°©ë²•(ì˜ˆ: í•™êµ ì…í•™ì²˜/í•™ê³¼ ì»¤ë¦¬í˜ëŸ¼/ì·¨ì—…í†µê³„ í™•ì¸)ì„ ì•ˆë‚´í•œë‹¤.

ì´ì „ ëŒ€í™”:
{history}

ì‚¬ìš©ì ì§ˆë¬¸:
{question}

ë‹µë³€:
"""

fallback_chain = build_chain(FALLBACK_PROMPT)
intent_chain = build_chain(INTENT_PROMPT)
answer_chain = build_chain(ANSWER_PROMPT)
# ì¶”ì²œ ìš”ì•½ APIì—ì„œ ì‚¬ìš©í•  LLM í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ë‹¤.
# í”„ë¡ íŠ¸ê°€ í•„ìš”í•œ JSON ìŠ¤í‚¤ë§ˆë¥¼ ì •í™•íˆ ë§ì¶”ë„ë¡ ê°•ì œí•˜ê¸° ìœ„í•´
# ì…ë ¥ í•„ë“œì™€ ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ëª…ì‹œí•˜ê³ , JSON ì™¸ í…ìŠ¤íŠ¸ ì¶œë ¥ ê¸ˆì§€ ê·œì¹™ì„ í¬í•¨í•œë‹¤.
SUMMARY_PROMPT = """
ë„ˆëŠ” ëŒ€í•™/í•™ê³¼ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ìš”ì•½ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ìƒì„±í•œë‹¤.
ë°˜ë“œì‹œ ì•„ë˜ ìŠ¤í‚¤ë§ˆë¥¼ ì§€ì¼œì„œ JSONë§Œ ì¶œë ¥í•´ë¼. ë§ˆí¬ë‹¤ìš´/ì„¤ëª… ê¸ˆì§€.

[ì…ë ¥]
- ì´ì „ ëŒ€í™”: {history}
- ì‚¬ìš©ì ì§ˆë¬¸: {question}
- ì¶”ì²œ í›„ë³´ ë°ì´í„°:
{context}

[ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ]
{{
  "departments": [
    {{
      "name": "í•™ê³¼ëª…",
      "university": "ëŒ€í•™ëª…",
      "matchScore": 0-100 ì •ìˆ˜,
      "employmentRate": 0-100 ì •ìˆ˜,
      "averageSalary": ë§Œì› ë‹¨ìœ„ ì •ìˆ˜,
      "competitionRate": ì‹¤ìˆ˜,
      "requiredGrade": "ì˜ˆ: 2.3ë“±ê¸‰",
      "description": "ì¶”ì²œ ì´ìœ  ìš”ì•½",
      "relatedJobs": ["ì§ì—…1", "ì§ì—…2"],
      "websiteUrl": "https://..."
    }}
  ],
  "userProfile": {{
    "interests": ["ê´€ì‹¬ì‚¬1", "ê´€ì‹¬ì‚¬2"],
    "strengths": [
      {{ "subject": "ê³¼ëª©", "score": 0-100 ì •ìˆ˜ }}
    ],
    "careerGoal": "ì§„ë¡œ ëª©í‘œ",
    "region": "í¬ë§ ì§€ì—­",
    "gradeLevel": "ê³ 1/ê³ 2/ê³ 3/ì¡¸ì—…"
  }},
  "initialConversations": [
    {{ "user": "ì§ˆë¬¸", "assistant": "ì‘ë‹µ" }}
  ],
  "afterRecommendationConversations": [
    {{ "user": "ì§ˆë¬¸", "assistant": "ì‘ë‹µ" }}
  ],
  "industryTrends": [
    {{ "year": "2020", "demand": 0-100 ì •ìˆ˜, "salary": ë§Œì› ë‹¨ìœ„ ì •ìˆ˜ }}
  ],
  "skillRequirements": [
    {{ "skill": "ì—­ëŸ‰", "importance": 0-100 ì •ìˆ˜ }}
  ]
}}

[ê·œì¹™]
- JSON ì™¸ í…ìŠ¤íŠ¸ ì¶œë ¥ ê¸ˆì§€.
- ê°’ì´ ë¶ˆí™•ì‹¤í•˜ë©´ ì¶”ì •í•˜ë˜, ì§ˆë¬¸/í›„ë³´ ë°ì´í„°ì™€ ì¼ê´€ë˜ê²Œ ì‘ì„±.
"""
# ìš”ì•½ìš© í”„ë¡¬í”„íŠ¸ë¥¼ LLM ì²´ì¸ìœ¼ë¡œ êµ¬ì„±í•œë‹¤.
# ìš”ì•½ APIëŠ” ì´ ì²´ì¸ì„ í†µí•´ JSON í˜•íƒœì˜ ê²°ê³¼ë¥¼ ìƒì„±í•œë‹¤.
summary_chain = build_chain(SUMMARY_PROMPT)


# ======================================================
# 4) ë°ì´í„° ë¡œë”©
# ======================================================
print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")

info_df = pd.read_csv("A_embedding.csv").fillna("")
info_df.columns = info_df.columns.str.strip()

emb_df = pd.read_csv("A_embedding_vectors.csv").fillna("")
emb_df["embedding"] = emb_df["embedding"].apply(lambda x: np.array(ast.literal_eval(x)))

score_df = pd.read_csv("A_score.csv").fillna("")
score_df.columns = score_df.columns.str.strip()

school_df = pd.read_csv("school_score.csv").fillna("")
school_df.columns = (
    school_df.columns.str.replace("\n", "", regex=False).str.replace(" ", "", regex=False)
)

school_df = school_df.rename(columns={
    "í•™ë¬¸ì í‰íŒì ìˆ˜í•™ê³„ì—ì„œì–¼ë§ˆë‚˜ì¸ì •ë°›ëŠ”ëŒ€í•™ì¸ê°€": "í•™ë¬¸ì í‰íŒì ìˆ˜",
    "ì·¨ì—…í‰íŒì ìˆ˜ê¸°ì—…ì´ì„ í˜¸ë‚˜ëŠ”í•™êµì¸ê°€": "ì·¨ì—…í‰íŒì ìˆ˜",
    "êµìœ¡ë°€ë„êµìˆ˜ìˆ˜ëŒ€ë¹„í•™ìƒìˆ˜.í•™ìƒí•œëª…ì´êµìˆ˜ì—ê²Œì–¼ë§ˆë‚˜ì§‘ì¤‘ì§€ë„ë¥¼ë°›ì„ìˆ˜ìˆëŠ”ê°€": "êµìœ¡ë°€ë„",
    "êµìˆ˜ë‹¹ë…¼ë¬¸ì¸ìš©ìˆ˜êµìˆ˜ì˜ì§ˆ.": "êµìˆ˜ë‹¹ë…¼ë¬¸ì¸ìš©ìˆ˜",
    "êµ­ì œê³µë™ì—°êµ¬ìœ í•™í•´ì™¸ì—°êµ¬ê¸€ë¡œë²Œì§„ì¶œì—°ê²°ì„±": "êµ­ì œê³µë™ì—°êµ¬",
    "ì¡¸ì—…ìƒì„±ê³¼ì·¨ì—…ë¥ ì¡¸ì—…ìƒì—": "ì¡¸ì—…ìƒì„±ê³¼",
})

# ì„ë² ë”© ë³‘í•©
info_df["embedding"] = emb_df["embedding"].values
corpus_embeddings = np.vstack(info_df["embedding"].values)

# ì§€ì—­ ì»¬ëŸ¼ í†µì¼
if "ì†Œì¬ì§€(ìƒì„¸)" in info_df.columns:
    info_df["ì§€ì—­"] = info_df["ì†Œì¬ì§€(ìƒì„¸)"]
else:
    info_df["ì§€ì—­"] = info_df.get("ì†Œì¬ì§€", "")

# SentenceTransformer(ë¡œì»¬ ì„ë² ë”©)
model = SentenceTransformer("intfloat/multilingual-e5-base")

print("âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ")


# ======================================================
# 5) ê²€ìƒ‰ / í‰ê°€ 
# ======================================================
def search_major_contextual(user_query: str, top_k: int = 20) -> pd.DataFrame:
    query_emb = model.encode(
        "query: " + normalize_text(user_query),
        convert_to_numpy=True,
        normalize_embeddings=True
    )

    df = info_df.copy()
    df["sim"] = np.dot(corpus_embeddings, query_emb)
    return df.sort_values("sim", ascending=False).head(top_k)

def evaluate_retrieval(results_df: pd.DataFrame) -> bool:
    # ë„¤ ê¸°ì¡´ ê¸°ì¤€ ìœ ì§€(ì›í•˜ë©´ íŠœë‹)
    if results_df is None or results_df.empty:
        return False
    if float(results_df.iloc[0]["sim"]) < 0.80:
        return False
    if len(results_df) < 3:
        return False
    return True

def rerank_with_filters(results_df: pd.DataFrame, user_query: str) -> pd.DataFrame:
    """
    ê°„ë‹¨ ë¦¬ë­í‚¹:
    - ì¿¼ë¦¬ í‚¤ì›Œë“œ(ì§€ì—­/ì£¼ì•¼/í•™ê³¼íŠ¹ì„±/ê³„ì—´)ê°€ í¬í•¨ë˜ë©´ ê°€ì‚°ì 
    - ì™„ì „í•œ LLM rerankê°€ ì•„ë‹ˆë¼ ê·œì¹™ ê¸°ë°˜(ê°€ë³ê³  ë¹ ë¦„)
    """
    q = normalize_text(user_query)
    tokens = set(q.split())

    def bonus(row):
        text = " ".join([
            normalize_text(row.get("ëŒ€í•™ëª…", "")),
            normalize_text(row.get("í•™ê³¼ëª…", "")),
            normalize_text(row.get("ì§€ì—­", "")),
            normalize_text(row.get("ì£¼ì•¼êµ¬ë¶„", "")),
            normalize_text(row.get("í•™ê³¼íŠ¹ì„±", "")),
            normalize_text(row.get("í‘œì¤€ë¶„ë¥˜ê³„ì—´(ì¤‘)", "")),
        ])
        hit = sum(1 for t in tokens if t and t in text)
        return min(hit, 10) * 0.01  # ìµœëŒ€ +0.10

    df = results_df.copy()
    df["bonus"] = df.apply(bonus, axis=1)
    df["score"] = df["sim"] + df["bonus"]
    return df.sort_values("score", ascending=False)

def attach_score(results_df: pd.DataFrame, user_grade: float) -> pd.DataFrame:
    rows = []
    for _, row in results_df.iterrows():
        score_row = score_df[
            (score_df["ëŒ€í•™ëª…"] == row["ëŒ€í•™ëª…"]) &
            (score_df["í•™ê³¼ëª…"] == row["í•™ê³¼ëª…"])
        ]
        if score_row.empty:
            continue

        avg = safe_float(score_row.iloc[0].get("í•™ì "))
        if avg is None or user_grade is None:
            level = "ë‚´ì‹  íŒë‹¨ ë¶ˆê°€"
        else:
            if user_grade >= avg + 0.2:
                level = "í•˜í–¥"
            elif user_grade <= avg - 0.2:
                level = "ìƒí–¥"
            else:
                level = "ì ì •"

        school_row = school_df[school_df.get("í•™êµ") == row["ëŒ€í•™ëª…"]] if "í•™êµ" in school_df.columns else pd.DataFrame()
        school = school_row.iloc[0] if not school_row.empty else {}

        rows.append({
            "ëŒ€í•™ëª…": row.get("ëŒ€í•™ëª…"),
            "í•™ê³¼ëª…": row.get("í•™ê³¼ëª…"),
            "ì§€ì—­": row.get("ì§€ì—­"),
            "ì£¼ì•¼êµ¬ë¶„": row.get("ì£¼ì•¼êµ¬ë¶„", ""),
            "í•™ê³¼íŠ¹ì„±": row.get("í•™ê³¼íŠ¹ì„±", ""),
            "ê³„ì—´": row.get("í‘œì¤€ë¶„ë¥˜ê³„ì—´(ì¤‘)", ""),
            "ìœ ì‚¬ë„": float(row.get("sim", 0.0)),
            "ë³´ë„ˆìŠ¤": float(row.get("bonus", 0.0)),
            "ìµœì¢…ì ìˆ˜": float(row.get("score", 0.0)),

            "í‰ê· ë‚´ì‹ ": avg,
            "íŒë‹¨": level,

            "í•™ë¬¸í‰íŒ": school.get("í•™ë¬¸ì í‰íŒì ìˆ˜", "ë°ì´í„° ì—†ìŒ"),
            "ì·¨ì—…í‰íŒ": school.get("ì·¨ì—…í‰íŒì ìˆ˜", "ë°ì´í„° ì—†ìŒ"),
            "êµìœ¡ë°€ë„": school.get("êµìœ¡ë°€ë„", "ë°ì´í„° ì—†ìŒ"),
            "êµìˆ˜ì—°êµ¬ë ¥": school.get("êµìˆ˜ë‹¹ë…¼ë¬¸ì¸ìš©ìˆ˜", "ë°ì´í„° ì—†ìŒ"),
            "êµ­ì œí™”": school.get("êµ­ì œê³µë™ì—°êµ¬", "ë°ì´í„° ì—†ìŒ"),
            "ì¡¸ì—…ì„±ê³¼": school.get("ì¡¸ì—…ìƒì„±ê³¼", "ë°ì´í„° ì—†ìŒ"),
            "í•™êµìˆœìœ„": school.get("ìˆœìœ„", "ë°ì´í„° ì—†ìŒ"),
        })

    return pd.DataFrame(rows)


def build_context_text(rec_df: pd.DataFrame, top_n: int = 8) -> str:
    if rec_df is None or rec_df.empty:
        return ""

    rec_df = rec_df.head(top_n)
    blocks = []
    for i, r in rec_df.iterrows():
        blocks.append(
            f"[{len(blocks)+1}] {r['ëŒ€í•™ëª…']} / {r['í•™ê³¼ëª…']} ({r['ì§€ì—­']})\n"
            f"- ë‚´ì‹ íŒë‹¨: {r['íŒë‹¨']} (ì‚¬ìš©ì vs í‰ê· ë‚´ì‹  {r['í‰ê· ë‚´ì‹ ']})\n"
            f"- ì§€í‘œ: í•™ë¬¸í‰íŒ={r['í•™ë¬¸í‰íŒ']}, ì·¨ì—…í‰íŒ={r['ì·¨ì—…í‰íŒ']}, êµìœ¡ë°€ë„={r['êµìœ¡ë°€ë„']}, "
            f"êµìˆ˜ì—°êµ¬ë ¥={r['êµìˆ˜ì—°êµ¬ë ¥']}, êµ­ì œí™”={r['êµ­ì œí™”']}, ì¡¸ì—…ì„±ê³¼={r['ì¡¸ì—…ì„±ê³¼']}, ìˆœìœ„={r['í•™êµìˆœìœ„']}\n"
            f"- ê²€ìƒ‰ì ìˆ˜: sim={r['ìœ ì‚¬ë„']:.3f}, bonus={r['ë³´ë„ˆìŠ¤']:.3f}, score={r['ìµœì¢…ì ìˆ˜']:.3f}"
        )
    return "\n\n".join(blocks)


# Extract grade level hints from the user's message for summary personalization.
def extract_grade_level(text: str) -> str:
    if re.search(r"ê³ ë“±í•™êµ\\s*1í•™ë…„|ê³ 1", text):
        return "ê³ 1"
    if re.search(r"ê³ ë“±í•™êµ\\s*2í•™ë…„|ê³ 2", text):
        return "ê³ 2"
    if re.search(r"ê³ ë“±í•™êµ\\s*3í•™ë…„|ê³ 3", text):
        return "ê³ 3"
    if re.search(r"ì¡¸ì—…", text):
        return "ì¡¸ì—…"
    return "ë¯¸ìƒ"


# Extract preferred region keywords from the user's message for summary personalization.
def extract_region(text: str) -> str:
    region_map = {
        "ì„œìš¸": "ì„œìš¸",
        "ê²½ê¸°": "ê²½ê¸°/ì¸ì²œ",
        "ì¸ì²œ": "ê²½ê¸°/ì¸ì²œ",
        "ê°•ì›": "ê°•ì›",
        "ì¶©ì²­": "ì¶©ì²­",
        "ëŒ€ì „": "ì¶©ì²­",
        "ì„¸ì¢…": "ì¶©ì²­",
        "ì „ë¼": "ì „ë¼",
        "ê´‘ì£¼": "ì „ë¼",
        "ê²½ìƒ": "ê²½ìƒ",
        "ë¶€ì‚°": "ê²½ìƒ",
        "ëŒ€êµ¬": "ê²½ìƒ",
        "ìš¸ì‚°": "ê²½ìƒ",
        "ì œì£¼": "ì œì£¼",
    }
    for keyword, region in region_map.items():
        if keyword in text:
            return region
    return "ë¯¸ìƒ"


# Infer interest tags from user text to drive summary charts and skills.
def infer_interests(text: str) -> list[str]:
    keywords = [
        ("ì»´í“¨í„°", "ì»´í“¨í„°"),
        ("ì†Œí”„íŠ¸ì›¨ì–´", "ì†Œí”„íŠ¸ì›¨ì–´"),
        ("í”„ë¡œê·¸ë˜ë°", "í”„ë¡œê·¸ë˜ë°"),
        ("AI", "AI"),
        ("ì¸ê³µì§€ëŠ¥", "AI"),
        ("ì˜í•™", "ì˜í•™"),
        ("ê°„í˜¸", "ê°„í˜¸"),
        ("ì•½í•™", "ì•½í•™"),
        ("ê²½ì˜", "ê²½ì˜"),
        ("ê²½ì œ", "ê²½ì œ"),
        ("ë””ìì¸", "ë””ìì¸"),
        ("ì˜ˆìˆ ", "ì˜ˆìˆ "),
    ]
    interests = []
    for key, label in keywords:
        if key.lower() in text.lower() or key in text:
            if label not in interests:
                interests.append(label)
    return interests


# Extract a short career goal phrase when explicitly stated by the user.
def infer_career_goal(text: str) -> str:
    match = re.search(r"(?:ë˜ê³ \\s*ì‹¶|ê¿ˆ|ëª©í‘œ|í¬ë§).*", text)
    return match.group(0) if match else ""


# Convert raw chat history into user/assistant pairs for summary display.
def build_conversation_pairs(history: list[dict]) -> list[dict]:
    pairs = []
    pending_user = None
    for message in history:
        if message.get("role") == "user":
            pending_user = message.get("content", "")
        elif message.get("role") == "assistant" and pending_user:
            pairs.append({"user": pending_user, "assistant": message.get("content", "")})
            pending_user = None
    return pairs


# Parse the JSON-only summary response, trimming any stray text.
def parse_summary_json(raw: str) -> dict:
    start = raw.find("{")
    end = raw.rfind("}")
    if start != -1 and end != -1:
        raw = raw[start:end + 1]
    return json.loads(raw)


# Create lightweight trend series based on inferred interests.
def build_industry_trends(interests: list[str]) -> list[dict]:
    if not interests:
        return []
    base = 3600
    trends = []
    for idx, year in enumerate(["2020", "2021", "2022", "2023", "2024"]):
        trends.append({
            "year": year,
            "demand": min(95, 70 + idx * 6),
            "salary": base + idx * 150,
        })
    return trends


# Create lightweight skill requirements based on inferred interests.
def build_skill_requirements(interests: list[str]) -> list[dict]:
    if "AI" in interests or "ì»´í“¨í„°" in interests or "ì†Œí”„íŠ¸ì›¨ì–´" in interests or "í”„ë¡œê·¸ë˜ë°" in interests:
        return [
            {"skill": "í”„ë¡œê·¸ë˜ë°", "importance": 95},
            {"skill": "ìˆ˜í•™", "importance": 85},
            {"skill": "ë…¼ë¦¬ì  ì‚¬ê³ ", "importance": 90},
            {"skill": "ë¬¸ì œí•´ê²°", "importance": 88},
            {"skill": "ì˜ì–´", "importance": 75},
        ]
    if "ê²½ì˜" in interests or "ê²½ì œ" in interests:
        return [
            {"skill": "ë°ì´í„° ë¶„ì„", "importance": 88},
            {"skill": "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜", "importance": 85},
            {"skill": "ë¬¸ì œí•´ê²°", "importance": 82},
        ]
    if "ë””ìì¸" in interests:
        return [
            {"skill": "ì°½ì˜ì„±", "importance": 90},
            {"skill": "ì‚¬ìš©ì ì´í•´", "importance": 85},
            {"skill": "ë„êµ¬ í™œìš©", "importance": 80},
        ]
    return []


 


# ======================================================
# 6) API
# ======================================================
class ChatRequest(BaseModel):
    question: str
    session_id: str


VALID_INTENTS = {"RECOMMEND", "SCHOOL_INFO", "EXPLAIN_SYSTEM", "OTHER"}

def normalize_intent(raw: str) -> str:
    if not raw:
        return "OTHER"
    s = raw.strip().upper()
    s = s.split()[0].replace(":", "").replace("-", "_")
    return s if s in VALID_INTENTS else "OTHER"


@app.post("/chat")
def chat(req: ChatRequest):
    question = req.question.strip()
    session_id = req.session_id.strip()

    # 1) íˆìŠ¤í† ë¦¬
    history = get_history(session_id)
    history_text = history_to_text(history)

    # 2) ì˜ë„ ë¶„ë¥˜ + ë³´ì •
    raw_intent = intent_chain.invoke({"question": question})
    intent = normalize_intent(raw_intent)

    # 3) ê²€ìƒ‰ (RECOMMEND / SCHOOL_INFO ê³µí†µ)
    majors = search_major_contextual(question, top_k=20)
    use_rag = evaluate_retrieval(majors)

    # ===============================
    # ì˜ë„ë³„ ì²˜ë¦¬
    # ===============================
    if intent == "OTHER":
        answer = (
            "ì´ ì±—ë´‡ì€ ëŒ€í•™Â·í•™ê³¼ ì¶”ì²œì„ ìœ„í•œ ìƒë‹´ ì±—ë´‡ì´ì—ìš”.\n"
            "ì˜ˆë¥¼ ë“¤ë©´:\n"
            "- ì„œìš¸ì— ìˆëŠ” ì»´í“¨í„°ê³µí•™ê³¼ ì¶”ì²œí•´ì¤˜\n"
            "- ë‚´ì‹  3.2ì¸ë° ìˆ˜ë„ê¶Œ ê³µëŒ€ ê°€ëŠ¥í• ê¹Œ?\n"
            "ì²˜ëŸ¼ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."
        )

    elif intent == "EXPLAIN_SYSTEM":
        answer = (
            "ì´ ì‹œìŠ¤í…œì€ ì§ˆë¬¸ì„ ë¶„ì„í•´ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ê³ ,\n"
            "í•™ê³¼ ì„ë² ë”© ê²€ìƒ‰ + ë‚´ì‹  ë°ì´í„° + í•™êµ í‰íŒ ì§€í‘œë¥¼ ê²°í•©í•´\n"
            "í˜„ì‹¤ì ì¸ ëŒ€í•™Â·í•™ê³¼ ì¶”ì²œì„ ì œê³µí•´ìš”."
        )

    elif intent == "SCHOOL_INFO":
        # âœ… RAGê°€ ë¶€ì‹¤í•˜ë©´: RAG ì—†ì´ GPTë¡œ ì¼ë°˜ ì•ˆë‚´
        if not use_rag:
            answer = fallback_chain.invoke({
                "history": history_text,
                "question": question,
            }).strip()

        else:
            # RAGê°€ ì¶©ë¶„í•  ë•Œë§Œ: ê¸°ì¡´ì²˜ëŸ¼ top-1ë¡œ context êµ¬ì„±
            t = majors.iloc[0]
            context_text = (
                f"[1] {t.get('ëŒ€í•™ëª…','')} / {t.get('í•™ê³¼ëª…','')} ({t.get('ì§€ì—­','')})\n"
                f"- í•™ê³¼íŠ¹ì„±: {t.get('í•™ê³¼íŠ¹ì„±','ì •ë³´ ì—†ìŒ')}\n"
                f"- ê³„ì—´: {t.get('í‘œì¤€ë¶„ë¥˜ê³„ì—´(ì¤‘)','ì •ë³´ ì—†ìŒ')}"
            )

            answer = answer_chain.invoke({
                "history": history_text,
                "question": question,
                "intent": intent,
                "context": context_text
            }).strip()

    else:  # RECOMMEND
        # âœ… RAGê°€ ë¶€ì‹¤í•˜ë©´: RAG ì—†ì´ GPTë¡œ ì¼ë°˜ ìƒë‹´ + ì¶”ê°€ ì§ˆë¬¸
        if not use_rag:
            answer = fallback_chain.invoke({
                "history": history_text,
                "question": question,
            }).strip()

        else:
            user_grade = extract_grade(question)

            if user_grade is not None and majors is not None and not majors.empty:
                rec_df = attach_score(majors, user_grade)
                context_text = build_context_text(rec_df, top_n=5)
            else:
                # ë‚´ì‹  ì—†ì„ ë•Œ: ìµœì†Œ ì •ë³´ë§Œ
                blocks = []
                for _, r in majors.head(5).iterrows():
                    blocks.append(
                        f"- {r.get('ëŒ€í•™ëª…','')} / {r.get('í•™ê³¼ëª…','')} ({r.get('ì§€ì—­','')})"
                    )
                context_text = "\n".join(blocks)

            answer = answer_chain.invoke({
                "history": history_text,
                "question": question,
                "intent": intent,
                "context": context_text
            }).strip()

    # 4) íˆìŠ¤í† ë¦¬ ì €ì¥
    append_history(session_id, "user", question)
    append_history(session_id, "assistant", answer)

    return {
        "answer": answer,
        "intent": intent,
    }


# í”„ë¡ íŠ¸ ìš”ì•½ í™”ë©´ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” APIë‹¤.
# ëŒ€í™” ì´ë ¥ê³¼ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ê³ ,
# LLM ì‹¤íŒ¨ ì‹œì—ëŠ” ê·œì¹™ ê¸°ë°˜ ëŒ€ì²´ ê²°ê³¼ë¥¼ ë§Œë“ ë‹¤.
@app.post("/recommendation/summary", response_model=RecommendationSummaryResponse)
def recommendation_summary(req: RecommendationSummaryRequest):
    question = req.question.strip()
    session_id = req.session_id.strip()

    history = get_history(session_id)
    history_text = history_to_text(history)

    majors = search_major_contextual(question, top_k=20)
    if majors is not None and not majors.empty:
        majors = rerank_with_filters(majors, question)

    user_grade = extract_grade(question)
    if user_grade is not None and majors is not None and not majors.empty:
        rec_df = attach_score(majors, user_grade)
    else:
        rec_df = pd.DataFrame()

    payload = build_recommendation_summary_payload(question, history, history_text, rec_df, user_grade)
    return RecommendationSummaryResponse(**payload)


# ìš”ì•½ APIì˜ í•µì‹¬ í˜ì´ë¡œë“œ ìƒì„± í•¨ìˆ˜ë‹¤.
# LLMì´ JSONì„ ë°˜í™˜í•˜ë©´ ì´ë¥¼ íŒŒì‹±í•´ ì‚¬ìš©í•˜ê³ , íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ ê²°ê³¼ë¡œ ëŒ€ì²´í•œë‹¤.
def build_recommendation_summary_payload(
    question: str,
    history: list[dict],
    history_text: str,
    rec_df: pd.DataFrame,
    user_grade: float | None,
) -> dict:
    # ì¶”ì²œ í›„ë³´ ì¤‘ ìƒìœ„ í•­ëª©ì„ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½í•´ LLM ì…ë ¥ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µí•œë‹¤.
    context_text = build_context_text(rec_df, top_n=5) if rec_df is not None else ""
    raw = summary_chain.invoke({
        "history": history_text,
        "question": question,
        "context": context_text,
    }).strip()
    try:
        return parse_summary_json(raw)
    except Exception:
        return build_summary_fallback(question, history, rec_df, user_grade)


# LLMì´ JSONì„ ë°˜í™˜í•˜ì§€ ëª»í•˜ê±°ë‚˜ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ë˜ëŠ” ê·œì¹™ ê¸°ë°˜ ìš”ì•½ ìƒì„±ê¸°ë‹¤.
# ì¶”ì²œ í›„ë³´ ë°ì´í„°ì™€ ì§ˆë¬¸ ì •ë³´ë¥¼ ì¡°í•©í•´ í™”ë©´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ë§Œë“ ë‹¤.
def build_summary_fallback(
    question: str,
    history: list[dict],
    rec_df: pd.DataFrame,
    user_grade: float | None,
) -> dict:
    # ì§ˆë¬¸ì—ì„œ ê´€ì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì •í•´ ìš”ì•½ í™”ë©´ì˜ í”„ë¡œí•„/íŠ¸ë Œë“œ ë°ì´í„°ì— ë°˜ì˜í•œë‹¤.
    interests = infer_interests(question)
    user_profile = {
        "interests": interests,
        "strengths": [],
        "careerGoal": infer_career_goal(question),
        "region": extract_region(question),
        "gradeLevel": extract_grade_level(question),
    }

    departments = []
    # ì¶”ì²œ í›„ë³´ê°€ ìˆëŠ” ê²½ìš° ìƒìœ„ 5ê°œë¥¼ ìš”ì•½ í•­ëª©ìœ¼ë¡œ ë³€í™˜í•œë‹¤.
    if rec_df is not None and not rec_df.empty:
        for _, row in rec_df.head(5).iterrows():
            score_value = row.get("ìµœì¢…ì ìˆ˜") or row.get("ìœ ì‚¬ë„") or 0.75
            base_score = float(score_value) * 100

            # ë‚´ì‹  ì •ë³´ê°€ ìˆìœ¼ë©´ í‰ê·  ë‚´ì‹ ê³¼ì˜ ê²©ì°¨ë¥¼ ì ìˆ˜ì— ë°˜ì˜í•´ ì í•©ë„ë¥¼ ì¡°ì •í•œë‹¤.
            avg_grade = row.get("í‰ê· ë‚´ì‹ ")
            avg_grade_value = avg_grade if isinstance(avg_grade, (int, float)) else None
            if user_grade is not None and avg_grade_value is not None:
                grade_gap = user_grade - avg_grade_value
                gap_penalty = min(12, max(-6, grade_gap * 8))
                base_score -= gap_penalty

            match_score = int(min(95, max(65, base_score)))
            # ì·¨ì—…/í•™ë¬¸ í‰íŒì„ í™œìš©í•´ ì·¨ì—…ë¥ ê³¼ í‰ê·  ì—°ë´‰ì„ ì¶”ì •ì¹˜ë¡œ êµ¬ì„±í•œë‹¤.
            employment_score = safe_float(row.get("ì·¨ì—…í‰íŒ"))
            if employment_score is None:
                employment_rate = max(60, min(92, match_score - 3))
            else:
                employment_rate = int(min(95, max(55, employment_score)))

            research_score = safe_float(row.get("í•™ë¬¸í‰íŒ"))
            base_salary = 3000 + (match_score - 65) * 30
            if research_score is not None:
                base_salary += int((research_score - 60) * 6)
            avg_salary = int(max(2800, min(4800, base_salary)))

            # ê²½ìŸë¥ ì€ ì í•©ë„ì™€ ë°˜ë¹„ë¡€í•˜ë„ë¡ ë‹¨ìˆœí™”í•´ ì‹œê°í™”ìš© ê°’ìœ¼ë¡œ ë§Œë“ ë‹¤.
            competition_rate = round(4.0 + (95 - match_score) / 15, 1)
            required_grade = f"{avg_grade_value:.1f}ë“±ê¸‰" if avg_grade_value is not None else "ì •ë³´ ì—†ìŒ"
            major_name = row.get("í•™ê³¼ëª…", "") or "ì¶”ì²œ í•™ê³¼"
            university_name = row.get("ëŒ€í•™ëª…", "") or "ì¶”ì²œ ëŒ€í•™"
            region_name = row.get("ì§€ì—­", "")
            track = row.get("ê³„ì—´") or row.get("í‘œì¤€ë¶„ë¥˜ê³„ì—´(ì¤‘)") or ""
            major_feature = row.get("í•™ê³¼íŠ¹ì„±") or ""
            schedule = row.get("ì£¼ì•¼êµ¬ë¶„") or ""
            level = row.get("íŒë‹¨") or "ì ì •"
            summary = (
                f"{university_name} {major_name}ëŠ” {region_name} ì§€ì—­ ê¸°ì¤€ìœ¼ë¡œ {level} ì§€ì›ì— í•´ë‹¹í•©ë‹ˆë‹¤. "
                "í•™ê³¼ íŠ¹ì„±ê³¼ ì„±ì  ì í•©ë„ë¥¼ í•¨ê»˜ ê³ ë ¤í•´ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤."
            )
            detail_bits = []
            if track:
                detail_bits.append(f"ê³„ì—´: {track}")
            if major_feature:
                detail_bits.append(f"í•™ê³¼ íŠ¹ì„±: {major_feature}")
            if schedule:
                detail_bits.append(f"ìš´ì˜: {schedule}")
            if detail_bits:
                summary = f"{summary} " + " / ".join(detail_bits) + "."
            departments.append({
                "name": major_name,
                "university": university_name,
                "matchScore": match_score,
                "employmentRate": employment_rate,
                "averageSalary": avg_salary,
                "competitionRate": competition_rate,
                "requiredGrade": required_grade,
                "description": summary,
                "relatedJobs": infer_related_jobs(major_name),
                "websiteUrl": row.get("í™ˆí˜ì´ì§€", ""),
            })

    # ëŒ€í™” ì´ë ¥ì„ ìš”ì•½ í™”ë©´ì— í‘œì‹œí•  ìˆ˜ ìˆë„ë¡ ì‚¬ìš©ì/ì–´ì‹œìŠ¤í„´íŠ¸ í˜ì–´ë¡œ êµ¬ì„±í•œë‹¤.
    pairs = build_conversation_pairs(history)
    initial_pairs = pairs[:3]
    after_pairs = pairs[3:6]

    return {
        "departments": departments,
        "userProfile": user_profile,
        "initialConversations": initial_pairs,
        "afterRecommendationConversations": after_pairs,
        "industryTrends": build_industry_trends(interests),
        "skillRequirements": build_skill_requirements(interests),
    }

