# ======================================================
# ëŒ€í•™ Â· í•™ê³¼ ì¶”ì²œ API ì„œë²„
# FastAPI + Embedding + GPT-4o-mini
# ======================================================

import pandas as pd
import numpy as np
import ast
import re
import os

from sentence_transformers import SentenceTransformer
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI
from dotenv import load_dotenv


# ======================================================
# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env)
# ======================================================
load_dotenv()

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)


# ======================================================
# 2. FastAPI ì•± ìƒì„±
# ======================================================
app = FastAPI(
    title="ëŒ€í•™ Â· í•™ê³¼ ì¶”ì²œ ì±—ë´‡ API",
    description="Embedding + GPT ê¸°ë°˜ ëŒ€í•™ ì „ê³µ ì¶”ì²œ",
    version="1.0.0"
)

# ======================================================
# 3. CORS ì„¤ì •
# ======================================================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  origin í—ˆìš© (í”„ë¡œë•ì…˜ì—ì„œëŠ” ì œí•œ í•„ìš”)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ======================================================
# 4. í…ìŠ¤íŠ¸ ì •ê·œí™”
# ======================================================
def normalize_text(text: str) -> str:
    text = str(text)
    text = re.sub(r"[,\u00b7ãƒ»]", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()


# ======================================================
# 5. ê°•í™”ëœ ì˜ë„ ì¶”ì¶œ
# ======================================================
def extract_intent(text: str):
    """ì§€ì—­ê³¼ í•™ê³¼ ê³„ì—´/í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ"""

    # ì§€ì—­ í‚¤ì›Œë“œ
    regions = ["ì„œìš¸", "ê²½ê¸°", "ì¸ì²œ", "ë¶€ì‚°", "ëŒ€êµ¬", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°",
               "ê°•ì›", "ì¶©ì²­", "ì „ë¼", "ê²½ìƒ", "ì œì£¼"]

    # í•™ê³¼ ê³„ì—´ í‚¤ì›Œë“œ (í‘œì¤€ë¶„ë¥˜ê³„ì—´ê³¼ ë§¤ì¹­)
    major_categories = {
        "ì¸ë¬¸": ["ì¸ë¬¸", "ë¬¸í•™", "ì–´í•™", "ì² í•™", "ì—­ì‚¬", "êµ­ì–´", "ì˜ì–´", "ê¸€ì“°ê¸°", "ë²ˆì—­"],
        "ì‚¬íšŒ": ["ì‚¬íšŒ", "ê²½ì˜", "ê²½ì œ", "ë²•í•™", "í–‰ì •", "ì •ì¹˜", "ê¸°íš"],
        "êµìœ¡": ["êµìœ¡", "ìœ ì•„êµìœ¡", "êµì‚¬", "ìƒë‹´"],
        "ê³µí•™": ["ê³µí•™", "ì»´í“¨í„°", "ì†Œí”„íŠ¸ì›¨ì–´", "ì „ì", "ê¸°ê³„", "í™”í•™", "ê±´ì¶•",
                "í”„ë¡œê·¸ë˜ë°", "ì½”ë”©", "IT", "ì •ë³´", "ì „ê¸°", "ì œì‘", "ê¸°ìˆ "],
        "ìì—°": ["ìì—°", "ìˆ˜í•™", "ë¬¼ë¦¬", "í™”í•™", "ìƒë¬¼", "ê³¼í•™", "ì‹¤í—˜", "ì—°êµ¬",
                "ë°ì´í„°", "ë¶„ì„", "í†µê³„"],
        "ì˜ì•½": ["ì˜í•™", "ì•½í•™", "ê°„í˜¸", "ì˜ë£Œ", "ê±´ê°•", "ë³´ê±´"],
        "ì˜ˆì²´ëŠ¥": ["ì˜ˆìˆ ", "ë¯¸ìˆ ", "ìŒì•…", "ë””ìì¸", "ì²´ìœ¡", "ì°½ì‘", "ì˜ˆì²´ëŠ¥"]
    }

    # ì§€ì—­ ì¶”ì¶œ
    region = next((r for r in regions if r in text), None)

    # í•™ê³¼ ê³„ì—´ ì¶”ì¶œ
    detected_categories = []
    for category, keywords in major_categories.items():
        if any(keyword in text for keyword in keywords):
            detected_categories.append(category)

    # ëª¨ë“  í‚¤ì›Œë“œ ì¶”ì¶œ (ê²€ìƒ‰ì— ì‚¬ìš©)
    all_keywords = []
    for keywords in major_categories.values():
        all_keywords.extend([k for k in keywords if k in text])

    return region, detected_categories, all_keywords


# ======================================================
# 6. í•™ê³¼ DB + ì„ë² ë”© ë¡œë“œ (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ)
# ======================================================
print("ğŸ“‚ í•™ê³¼ ë²¡í„° DB ë¡œë”© ì¤‘...")

df = pd.read_csv("test_language.csv").fillna("")
df.columns = df.columns.str.strip()

# ğŸ”¥ ì»¬ëŸ¼ëª… ì˜¤íƒ€ ë³´ì •
df.rename(columns={"í‘œì¤€ë¶„ ë¥˜ê³„ì—´(ì†Œ)": "í‘œì¤€ë¶„ë¥˜ê³„ì—´(ì†Œ)"}, inplace=True)

# ğŸ”¥ ì§€ì—­ ì»¬ëŸ¼ í†µí•© (í•µì‹¬)
print("ğŸ“‹ CSV ì»¬ëŸ¼ ëª©ë¡:")
print(df.columns.tolist())
print("\nğŸ” ì†Œì¬ì§€ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°:")
location_columns = [col for col in df.columns if 'ì†Œì¬ì§€' in col or 'ì§€ì—­' in col or 'ì£¼ì†Œ' in col]
print(f"   ë°œê²¬ëœ ì»¬ëŸ¼: {location_columns}")

if "ì†Œì¬ì§€" in df.columns:
    df["ì§€ì—­"] = df["ì†Œì¬ì§€"]
    print(f"   âœ… 'ì†Œì¬ì§€' ì»¬ëŸ¼ ì‚¬ìš©")
elif "ì†Œì¬ì§€(ìƒì„¸)" in df.columns:
    df["ì§€ì—­"] = df["ì†Œì¬ì§€(ìƒì„¸)"]
    print(f"   âœ… 'ì†Œì¬ì§€(ìƒì„¸)' ì»¬ëŸ¼ ì‚¬ìš©")
else:
    df["ì§€ì—­"] = ""
    print(f"   âš ï¸  ì†Œì¬ì§€ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤! ì§€ì—­ í•„í„°ë§ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ğŸ”¥ ì„ë² ë”© ë¡œë“œ
df["embedding"] = df["embedding"].apply(
    lambda x: np.array(ast.literal_eval(x))
)
corpus_embeddings = np.vstack(df["embedding"].values)

# ğŸ”¥ ì„ë² ë”© ëª¨ë¸
model = SentenceTransformer("intfloat/multilingual-e5-base")

print("âœ… í•™ê³¼ DB ë¡œë”© ì™„ë£Œ")


# ======================================================
# 7. í•™ê³¼ ê²€ìƒ‰ ë¡œì§
# ======================================================
def search_major(user_query: str, top_k: int = 5):
    # ì „ì—­ dfë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šë„ë¡ ë¨¼ì € ë³µì‚¬
    df_work = df.copy()

    print(f"\n{'='*60}")
    print(f"ğŸ” ê²€ìƒ‰ ì‹œì‘: {user_query[:100]}...")
    print(f"ì „ì²´ í•™ê³¼ ìˆ˜: {len(df_work)}")

    # ì„ë² ë”© ê²€ìƒ‰
    query = "query: " + normalize_text(user_query)
    query_embedding = model.encode(
        query,
        convert_to_numpy=True,
        normalize_embeddings=True
    )

    scores = np.dot(corpus_embeddings, query_embedding)
    df_work["score"] = scores

    # ì˜ë„ ì¶”ì¶œ (ì§€ì—­, ê³„ì—´, í‚¤ì›Œë“œ)
    region, categories, keywords = extract_intent(user_query)

    print(f"ğŸ“ ê°ì§€ëœ ì§€ì—­: {region}")
    print(f"ğŸ“š ê°ì§€ëœ ê³„ì—´: {categories}")
    print(f"ğŸ”‘ ê°ì§€ëœ í‚¤ì›Œë“œ: {keywords}")

    df_filtered = df_work

    # ğŸ”¥ ì§€ì—­ í•„í„°
    if region and "ì§€ì—­" in df_filtered.columns:
        before_count = len(df_filtered)

        # ì§€ì—­ í•„í„° ì ìš© ì „ ìƒ˜í”Œ ì¶œë ¥
        if before_count > 0:
            sample_regions = df_work["ì§€ì—­"].dropna().unique()[:20]
            print(f"ğŸ“ CSVì˜ ì‹¤ì œ ì§€ì—­ ê°’ ìƒ˜í”Œ: {list(sample_regions)}")

        df_filtered = df_filtered[
            df_filtered["ì§€ì—­"]
            .astype(str)
            .str.contains(region, na=False)
        ]
        print(f"âœ… ì§€ì—­ í•„í„° ì ìš©: {before_count} -> {len(df_filtered)} ('{region}' í¬í•¨)")

        # ë§¤ì¹­ ì•ˆ ëœ ê²½ìš° ê²½ê³ 
        if len(df_filtered) == 0 and before_count > 0:
            print(f"âš ï¸  '{region}'ê³¼ ë§¤ì¹­ë˜ëŠ” ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤!")

    # ğŸ”¥ í‘œì¤€ê³„ì—´ í•„í„° (ìƒˆë¡œ ì¶”ê°€!)
    if categories and "í‘œì¤€ë¶„ë¥˜ê³„ì—´(ì¤‘)" in df_filtered.columns:
        before_count = len(df_filtered)
        # ê³„ì—´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ì„ íƒ
        category_filter = df_filtered["í‘œì¤€ë¶„ë¥˜ê³„ì—´(ì¤‘)"].apply(
            lambda x: any(cat in str(x) for cat in categories)
        )
        df_filtered = df_filtered[category_filter]
        print(f"âœ… ê³„ì—´ í•„í„° ì ìš©: {before_count} -> {len(df_filtered)} (ê³„ì—´: {categories})")

        # ë§¤ì¹­ ì•ˆ ëœ ê²½ìš° ìƒ˜í”Œ ì¶œë ¥
        if len(df_filtered) == 0 and before_count > 0:
            print(f"âš ï¸  CSVì˜ ì‹¤ì œ ê³„ì—´ ê°’ ìƒ˜í”Œ:")
            sample_categories = df_work["í‘œì¤€ë¶„ë¥˜ê³„ì—´(ì¤‘)"].dropna().unique()[:10]
            print(f"   {list(sample_categories)}")

    # ğŸ”¥ í‚¤ì›Œë“œë¡œ í•™ê³¼ëª…/í•™ê³¼íŠ¹ì„± í•„í„° (ì¶”ê°€ ì •í™•ë„ í–¥ìƒ)
    if keywords:
        for keyword in keywords[:3]:  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œë§Œ
            if "í•™ê³¼ëª…" in df_filtered.columns:
                keyword_filter = (
                    df_filtered["í•™ê³¼ëª…"].astype(str).str.contains(keyword, case=False, na=False) |
                    df_filtered["í•™ê³¼íŠ¹ì„±"].astype(str).str.contains(keyword, case=False, na=False)
                )
                # í‚¤ì›Œë“œ ë§¤ì¹˜ëœ í•­ëª©ì— ì ìˆ˜ ê°€ì‚°
                df_filtered.loc[keyword_filter, "score"] += 0.1

    print(f"ğŸ“Š ìµœì¢… ê²°ê³¼: {len(df_filtered)}ê°œ í•™ê³¼")
    print(f"{'='*60}\n")

    # ì ìˆ˜ìˆœ ì •ë ¬ í›„ ìƒìœ„ ë°˜í™˜
    return df_filtered.sort_values(
        "score",
        ascending=False
    ).head(top_k)


# ======================================================
# 8. GPT í”„ë¡¬í”„íŠ¸ ìƒì„±
# ======================================================
def build_gpt_prompt(user_query: str, results_df: pd.DataFrame):
    context = ""

    for _, row in results_df.iterrows():
        context += f"""
ëŒ€í•™ëª…: {row.get('ëŒ€í•™ëª…', '')}
í•™ê³¼ëª…: {row.get('í•™ê³¼ëª…', '')}
ì†Œì¬ì§€: {row.get('ì§€ì—­', '')}
í•™ê³¼íŠ¹ì„±: {row.get('í•™ê³¼íŠ¹ì„±', '')}
í‘œì¤€ê³„ì—´: {row.get('í‘œì¤€ë¶„ë¥˜ê³„ì—´(ì¤‘)', '')}
---
"""

    return f"""
ë„ˆëŠ” í•œêµ­ì˜ ëŒ€í•™ ì…ì‹œ ë° ì§„ë¡œ ì „ë¬¸ ìƒë‹´ ì±—ë´‡ì´ë‹¤.

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_query}

[ì¶”ì²œ ê°€ëŠ¥í•œ í•™ê³¼ ì •ë³´]
{context}

ìš”ì²­ì‚¬í•­:
1. ì§ˆë¬¸ì— ë§ëŠ” í•™ê³¼ë¥¼ ì¶”ì²œí•´ë¼
2. ê° í•™ê³¼ì˜ íŠ¹ì§•ì„ ì‰½ê²Œ ì„¤ëª…í•´ë¼
3. ì¡¸ì—… í›„ ì§„ë¡œì™€ ì „ë§ì„ ì„¤ëª…í•´ë¼
4. ì¹œì ˆí•œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ë¼
5. ì œê³µëœ ì •ë³´ ì™¸ì˜ ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ˆë¼
"""


# ======================================================
# 9. GPT í˜¸ì¶œ
# ======================================================
def call_gpt4_mini(prompt: str) -> str:
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ëŒ€í•™ ì…ì‹œ ì „ë¬¸ ìƒë‹´ ì±—ë´‡ì´ë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.4
    )
    return response.choices[0].message.content


# ======================================================
# 10. API ìš”ì²­ / ì‘ë‹µ ëª¨ë¸
# ======================================================
class ChatRequest(BaseModel):
    question: str


class ChatResponse(BaseModel):
    answer: str


# ======================================================
# 11. í•µì‹¬ API ì—”ë“œí¬ì¸íŠ¸
# ======================================================
@app.post("/chat", response_model=ChatResponse)
def chat(req: ChatRequest):
    results = search_major(req.question)

    if results.empty:
        return ChatResponse(
            answer="ì¡°ê±´ì— ë§ëŠ” í•™ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë°”ê¿”ë³´ì„¸ìš”."
        )

    prompt = build_gpt_prompt(req.question, results)
    answer = call_gpt4_mini(prompt)

    return ChatResponse(answer=answer)
